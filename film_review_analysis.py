"""
è§‚ä¼—å½±è¯„æ•°æ®æŒ–æ˜åˆ†æç³»ç»Ÿ
ä½œè€…ï¼šClaude Code
æ—¥æœŸï¼š2025-11-08
åŠŸèƒ½ï¼šå¯¹ç”µå½±è¯„è®ºæ•°æ®è¿›è¡Œå…¨é¢çš„æ•°æ®æŒ–æ˜å’Œå¯è§†åŒ–åˆ†æ
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import jieba
import jieba.analyse
from collections import Counter
from wordcloud import WordCloud
import warnings
from datetime import datetime
import re
from matplotlib import font_manager

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
sns.set_palette("husl")


def _configure_chinese_font():
    """é…ç½® Matplotlib å­—ä½“ï¼Œç¡®ä¿ä¸­æ–‡æ­£å¸¸æ˜¾ç¤ºå¹¶è¿”å›å¯ç”¨å­—ä½“ä¿¡æ¯ã€‚"""
    candidate_fonts = [
        ("SimHei", ["simhei.ttf"]),
        ("Microsoft YaHei", ["msyh.ttc", "msyh.ttf"]),
        ("SimSun", ["simsun.ttc", "simsun.ttf"]),
        ("PingFang SC", ["PingFang.ttc", "PingFang Regular.ttf"]),
        ("Noto Sans CJK SC", ["NotoSansCJK-Regular.ttc", "NotoSansCJKsc-Regular.otf"]),
        ("Source Han Sans CN", ["SourceHanSansCN-Regular.otf", "SourceHanSansSC-Regular.otf"]),
    ]

    fm = font_manager.fontManager
    available_by_name = {f.name.lower(): f.fname for f in fm.ttflist}

    def _set_rc(font_name_to_use):
        plt.rcParams['font.sans-serif'] = [font_name_to_use]
        plt.rcParams['font.family'] = 'sans-serif'

    search_dirs = [
        os.path.join(os.environ.get("WINDIR", "C:/Windows"), "Fonts"),
        "/System/Library/Fonts",
        "/Library/Fonts",
        os.path.expanduser("~/Library/Fonts"),
        "/usr/share/fonts",
        "/usr/local/share/fonts",
        os.path.expanduser("~/.local/share/fonts"),
    ]

    for font_name, file_names in candidate_fonts:
        try:
            found_path = font_manager.findfont(font_name, fallback_to_default=False)
            if found_path and os.path.exists(found_path):
                actual_name = font_manager.FontProperties(fname=found_path).get_name()
                _set_rc(actual_name)
                return actual_name, found_path
        except Exception:
            pass

        lower_name = font_name.lower()
        if lower_name in available_by_name:
            font_path = available_by_name[lower_name]
            actual_name = font_manager.FontProperties(fname=font_path).get_name() if os.path.exists(font_path) else font_name
            _set_rc(actual_name)
            return actual_name, font_path

        for file_name in file_names:
            for directory in search_dirs:
                candidate_path = os.path.join(directory, file_name)
                if os.path.exists(candidate_path):
                    try:
                        fm.addfont(candidate_path)
                        actual_name = font_manager.FontProperties(fname=candidate_path).get_name()
                        _set_rc(actual_name)
                        return actual_name, candidate_path
                    except Exception:
                        continue

    return None, None


CHINESE_FONT_NAME, CHINESE_FONT_PATH = _configure_chinese_font()


class FilmReviewAnalyzer:
    """
    å½±è¯„æ•°æ®åˆ†æå™¨
    """

    def __init__(self, data_path):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        å‚æ•°:
            data_path: Excelæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        print("=" * 60)
        print("ğŸ¬ å½±è¯„æ•°æ®æŒ–æ˜åˆ†æç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)

        self.data_path = data_path
        self.df = None
        self.output_dir = "analysis_results"
        self.report = []
        self.wordcloud_font_path = CHINESE_FONT_PATH

        if CHINESE_FONT_NAME:
            print(f"âœ… æ£€æµ‹åˆ°ä¸­æ–‡å­—ä½“: {CHINESE_FONT_NAME}")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_dir}")

    def load_data(self):
        """
        åŠ è½½å¹¶åˆæ­¥æ£€æŸ¥æ•°æ®
        """
        print("\nğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®...")
        self.df = pd.read_excel(self.data_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(self.df)} æ¡è®°å½•ï¼Œ{len(self.df.columns)} ä¸ªå­—æ®µ")

        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        print(f"   - ç”µå½±æ•°é‡: {self.df['Movie_Name'].nunique()} éƒ¨")
        print(f"   - è¯„è®ºæ•°é‡: {len(self.df)} æ¡")
        print(f"   - ç”¨æˆ·æ•°é‡: {self.df['Username'].nunique()} äºº")
        print(f"   - æ—¶é—´èŒƒå›´: {self.df['Date'].min()} è‡³ {self.df['Date'].max()}")

        self.report.append("# å½±è¯„æ•°æ®æŒ–æ˜åˆ†ææŠ¥å‘Š\n")
        self.report.append(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        self.report.append(f"**æ•°æ®è§„æ¨¡**: {len(self.df)} æ¡è®°å½•\n")
        self.report.append(f"**ç”µå½±æ•°é‡**: {self.df['Movie_Name'].nunique()} éƒ¨\n\n")

    def preprocess_data(self):
        """
        æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—
        """
        print("\nğŸ§¹ å¼€å§‹æ•°æ®é¢„å¤„ç†...")

        # 1. å¤„ç†ç¼ºå¤±å€¼
        print("   - å¤„ç†ç¼ºå¤±å€¼...")
        missing_before = self.df.isnull().sum().sum()
        self.df['Comment'].fillna('', inplace=True)
        self.df['Username'].fillna('åŒ¿åç”¨æˆ·', inplace=True)
        missing_after = self.df.isnull().sum().sum()
        print(f"     å¤„ç†å‰ç¼ºå¤±å€¼: {missing_before}, å¤„ç†å: {missing_after}")

        # 2. æ·»åŠ è¯„è®ºé•¿åº¦ç‰¹å¾
        print("   - æå–è¯„è®ºé•¿åº¦ç‰¹å¾...")
        self.df['comment_length'] = self.df['Comment'].apply(lambda x: len(str(x)))

        # 3. æ·»åŠ æƒ…æ„Ÿåˆ†ç±»ï¼ˆåŸºäºæ˜Ÿçº§ï¼‰
        print("   - æ·»åŠ æƒ…æ„Ÿåˆ†ç±»...")
        def classify_sentiment(star):
            if star <= 2:
                return 'è´Ÿé¢'
            elif star == 3:
                return 'ä¸­æ€§'
            else:
                return 'æ­£é¢'

        self.df['sentiment'] = self.df['Star'].apply(classify_sentiment)

        # 4. æ—¶é—´ç‰¹å¾æå–
        print("   - æå–æ—¶é—´ç‰¹å¾...")
        self.df['year'] = pd.to_datetime(self.df['Date']).dt.year
        self.df['month'] = pd.to_datetime(self.df['Date']).dt.month
        self.df['year_month'] = pd.to_datetime(self.df['Date']).dt.to_period('M')

        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")

        # ç»Ÿè®¡ä¿¡æ¯
        sentiment_dist = self.df['sentiment'].value_counts()
        self.report.append("## ä¸€ã€æƒ…æ„Ÿåˆ†å¸ƒ\n")
        for sent, count in sentiment_dist.items():
            pct = count / len(self.df) * 100
            self.report.append(f"- **{sent}**: {count} æ¡ ({pct:.2f}%)\n")
        self.report.append("\n")

    def sentiment_analysis(self):
        """
        æƒ…æ„Ÿåˆ†æ
        """
        print("\nğŸ˜Š å¼€å§‹æƒ…æ„Ÿåˆ†æ...")

        # 1. æ˜Ÿçº§åˆ†å¸ƒé¥¼å›¾
        print("   - ç”Ÿæˆæ˜Ÿçº§åˆ†å¸ƒé¥¼å›¾...")
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        star_counts = self.df['Star'].value_counts().sort_index()
        colors = ['#ff6b6b', '#f06595', '#ffa500', '#74c0fc', '#51cf66']
        axes[0].pie(
            star_counts.values,
            labels=[f'{i}æ˜Ÿ' for i in star_counts.index],
            autopct='%1.1f%%',
            colors=colors,
            startangle=90
        )
        axes[0].set_title('ç”¨æˆ·æ˜Ÿçº§è¯„åˆ†åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        sentiment_counts = self.df['sentiment'].value_counts()
        sentiment_colors = {'æ­£é¢': '#51cf66', 'ä¸­æ€§': '#ffa500', 'è´Ÿé¢': '#ff6b6b'}
        axes[1].pie(
            sentiment_counts.values,
            labels=sentiment_counts.index,
            autopct='%1.1f%%',
            colors=[sentiment_colors[s] for s in sentiment_counts.index],
            startangle=90
        )
        axes[1].set_title('æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/01_sentiment_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 01_sentiment_distribution.png")

        # 2. è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾
        print("   - ç”Ÿæˆè¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾...")
        fig, ax = plt.subplots(figsize=(12, 6))

        ax.hist(self.df['Score'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
        ax.axvline(self.df['Score'].mean(), color='red', linestyle='--',
                  linewidth=2, label=f'å¹³å‡åˆ†: {self.df["Score"].mean():.2f}')
        ax.axvline(self.df['Score'].median(), color='green', linestyle='--',
                  linewidth=2, label=f'ä¸­ä½æ•°: {self.df["Score"].median():.2f}')

        ax.set_xlabel('ç”µå½±è¯„åˆ†', fontsize=12)
        ax.set_ylabel('ç”µå½±æ•°é‡', fontsize=12)
        ax.set_title('ç”µå½±è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
        ax.legend(fontsize=11)
        ax.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/02_score_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 02_score_distribution.png")

        print("âœ… æƒ…æ„Ÿåˆ†æå®Œæˆï¼")

    def keyword_analysis(self):
        """
        å…³é”®è¯åˆ†æå’Œè¯äº‘ç”Ÿæˆ
        """
        print("\nğŸ”¤ å¼€å§‹å…³é”®è¯åˆ†æ...")

        # åŠ è½½åœç”¨è¯
        print("   - åŠ è½½åœç”¨è¯è¡¨...")
        stopwords = self._load_stopwords()

        # åˆ†è¯
        print("   - å¯¹è¯„è®ºæ–‡æœ¬è¿›è¡Œåˆ†è¯...")
        all_words = []
        positive_words = []
        negative_words = []

        for idx, row in self.df.iterrows():
            if idx % 50000 == 0:
                print(f"     å¤„ç†è¿›åº¦: {idx}/{len(self.df)}")

            comment = str(row['Comment'])
            if len(comment) < 2:
                continue

            words = jieba.lcut(comment)
            words = [w for w in words if len(w) > 1 and w not in stopwords]

            all_words.extend(words)

            if row['sentiment'] == 'æ­£é¢':
                positive_words.extend(words)
            elif row['sentiment'] == 'è´Ÿé¢':
                negative_words.extend(words)

        print(f"     âœ… åˆ†è¯å®Œæˆï¼å…±æå– {len(all_words)} ä¸ªè¯")

        # 1. è¯é¢‘ç»Ÿè®¡
        print("   - ç»Ÿè®¡è¯é¢‘...")
        word_freq = Counter(all_words)
        top_words = word_freq.most_common(50)

        # ä¿å­˜TOPè¯æ±‡
        self.report.append("## äºŒã€å…³é”®è¯åˆ†æ\n")
        self.report.append("### TOP 20 é«˜é¢‘è¯æ±‡\n")
        for i, (word, freq) in enumerate(top_words[:20], 1):
            self.report.append(f"{i}. **{word}**: {freq} æ¬¡\n")
        self.report.append("\n")

        # 2. ç»˜åˆ¶è¯é¢‘æŸ±çŠ¶å›¾
        print("   - ç”Ÿæˆè¯é¢‘æŸ±çŠ¶å›¾...")
        fig, ax = plt.subplots(figsize=(14, 8))

        words, freqs = zip(*top_words[:30])
        bars = ax.barh(range(len(words)), freqs, color=plt.cm.viridis(np.linspace(0, 1, len(words))))
        ax.set_yticks(range(len(words)))
        ax.set_yticklabels(words)
        ax.invert_yaxis()
        ax.set_xlabel('è¯é¢‘', fontsize=12)
        ax.set_title('TOP 30 é«˜é¢‘å…³é”®è¯', fontsize=14, fontweight='bold')
        ax.grid(axis='x', alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, freq) in enumerate(zip(bars, freqs)):
            ax.text(freq + max(freqs)*0.01, i, f'{freq}',
                   va='center', fontsize=9)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/03_top_keywords.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 03_top_keywords.png")

        # 3. ç”Ÿæˆè¯äº‘
        print("   - ç”Ÿæˆè¯äº‘å›¾...")

        if not self.wordcloud_font_path:
            print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸­æ–‡å­—ä½“æ–‡ä»¶ï¼Œå·²è·³è¿‡è¯äº‘å›¾ç”Ÿæˆã€‚")
            self.report.append("âš ï¸ ç”±äºç³»ç»Ÿç¼ºå°‘ä¸­æ–‡å­—ä½“ï¼Œè¯äº‘å›¾æœªç”Ÿæˆã€‚\n\n")
            print("âœ… å…³é”®è¯åˆ†æå®Œæˆï¼")
            return word_freq

        font_path = self.wordcloud_font_path

        # æ•´ä½“è¯äº‘
        wordcloud = WordCloud(
            font_path=font_path,
            width=1600,
            height=800,
            background_color='white',
            max_words=200,
            colormap='viridis'
        ).generate(' '.join(all_words))

        fig, axes = plt.subplots(1, 3, figsize=(24, 8))

        # å…¨éƒ¨è¯„è®ºè¯äº‘
        axes[0].imshow(wordcloud, interpolation='bilinear')
        axes[0].axis('off')
        axes[0].set_title('å…¨éƒ¨è¯„è®ºè¯äº‘', fontsize=14, fontweight='bold', pad=20)

        # æ­£é¢è¯„è®ºè¯äº‘
        if positive_words:
            positive_wc = WordCloud(
                font_path=font_path,
                width=1600,
                height=800,
                background_color='white',
                max_words=150,
                colormap='Greens'
            ).generate(' '.join(positive_words))

            axes[1].imshow(positive_wc, interpolation='bilinear')
            axes[1].axis('off')
            axes[1].set_title('æ­£é¢è¯„è®ºè¯äº‘', fontsize=14, fontweight='bold', pad=20)

        # è´Ÿé¢è¯„è®ºè¯äº‘
        if negative_words:
            negative_wc = WordCloud(
                font_path=font_path,
                width=1600,
                height=800,
                background_color='white',
                max_words=150,
                colormap='Reds'
            ).generate(' '.join(negative_words))

            axes[2].imshow(negative_wc, interpolation='bilinear')
            axes[2].axis('off')
            axes[2].set_title('è´Ÿé¢è¯„è®ºè¯äº‘', fontsize=14, fontweight='bold', pad=20)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/04_wordcloud.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 04_wordcloud.png")

        print("âœ… å…³é”®è¯åˆ†æå®Œæˆï¼")

        return word_freq

    def movie_analysis(self):
        """
        ç”µå½±è¯„åˆ†å’Œäº’åŠ¨åˆ†æ
        """
        print("\nğŸ¥ å¼€å§‹ç”µå½±åˆ†æ...")

        # 1. çƒ­é—¨ç”µå½±TOP10
        print("   - åˆ†æçƒ­é—¨ç”µå½±TOP10...")
        movie_stats = self.df.groupby('Movie_Name').agg({
            'Score': 'first',
            'ID': 'count',
            'Like': 'sum',
            'Star': 'mean'
        }).rename(columns={'ID': 'review_count', 'Like': 'total_likes', 'Star': 'avg_star'})

        top_movies = movie_stats.nlargest(10, 'review_count')

        self.report.append("## ä¸‰ã€çƒ­é—¨ç”µå½± TOP 10\n")
        for i, (movie, row) in enumerate(top_movies.iterrows(), 1):
            self.report.append(f"{i}. **{movie}**\n")
            self.report.append(f"   - è¯„åˆ†: {row['Score']:.1f}\n")
            self.report.append(f"   - è¯„è®ºæ•°: {int(row['review_count'])} æ¡\n")
            self.report.append(f"   - å¹³å‡æ˜Ÿçº§: {row['avg_star']:.2f}\n")
            self.report.append(f"   - æ€»ç‚¹èµæ•°: {int(row['total_likes'])}\n\n")

        # ç»˜åˆ¶TOP10ç”µå½±æŸ±çŠ¶å›¾
        fig, axes = plt.subplots(2, 1, figsize=(14, 12))

        # è¯„è®ºæ•°TOP10
        ax1 = axes[0]
        movies = [m[:15]+'...' if len(m) > 15 else m for m in top_movies.index]
        bars1 = ax1.barh(range(len(movies)), top_movies['review_count'],
                        color=plt.cm.Spectral(np.linspace(0, 1, len(movies))))
        ax1.set_yticks(range(len(movies)))
        ax1.set_yticklabels(movies)
        ax1.invert_yaxis()
        ax1.set_xlabel('è¯„è®ºæ•°', fontsize=12)
        ax1.set_title('TOP 10 è¯„è®ºæœ€å¤šçš„ç”µå½±', fontsize=14, fontweight='bold')
        ax1.grid(axis='x', alpha=0.3)

        for i, (bar, count) in enumerate(zip(bars1, top_movies['review_count'])):
            ax1.text(count + max(top_movies['review_count'])*0.01, i,
                    f"{int(count)}", va='center', fontsize=9)

        # è¯„åˆ†æœ€é«˜TOP10
        top_rated = movie_stats.nlargest(10, 'Score')
        movies2 = [m[:15]+'...' if len(m) > 15 else m for m in top_rated.index]
        bars2 = axes[1].barh(range(len(movies2)), top_rated['Score'],
                            color=plt.cm.RdYlGn(np.linspace(0.3, 1, len(movies2))))
        axes[1].set_yticks(range(len(movies2)))
        axes[1].set_yticklabels(movies2)
        axes[1].invert_yaxis()
        axes[1].set_xlabel('è¯„åˆ†', fontsize=12)
        axes[1].set_title('TOP 10 è¯„åˆ†æœ€é«˜çš„ç”µå½±', fontsize=14, fontweight='bold')
        axes[1].grid(axis='x', alpha=0.3)
        axes[1].set_xlim(0, 10)

        for i, (bar, score) in enumerate(zip(bars2, top_rated['Score'])):
            axes[1].text(score + 0.1, i, f'{score:.1f}', va='center', fontsize=9)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/05_top_movies.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 05_top_movies.png")

        # 2. ç‚¹èµæ•°åˆ†æ
        print("   - åˆ†æç‚¹èµæ•°åˆ†å¸ƒ...")
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))

        # ç‚¹èµæ•°ç®±çº¿å›¾ï¼ˆæŒ‰æ˜Ÿçº§ï¼‰
        self.df.boxplot(column='Like', by='Star', ax=axes[0])
        axes[0].set_xlabel('æ˜Ÿçº§', fontsize=12)
        axes[0].set_ylabel('ç‚¹èµæ•°', fontsize=12)
        axes[0].set_title('ä¸åŒæ˜Ÿçº§è¯„è®ºçš„ç‚¹èµæ•°åˆ†å¸ƒ', fontsize=13, fontweight='bold')
        axes[0].get_figure().suptitle('')

        # ç‚¹èµæ•°åˆ†å¸ƒï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        like_data = self.df[self.df['Like'] > 0]['Like']
        axes[1].hist(np.log10(like_data + 1), bins=50, color='coral', edgecolor='black', alpha=0.7)
        axes[1].set_xlabel('log10(ç‚¹èµæ•°+1)', fontsize=12)
        axes[1].set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
        axes[1].set_title('ç‚¹èµæ•°åˆ†å¸ƒ (å¯¹æ•°å°ºåº¦)', fontsize=13, fontweight='bold')
        axes[1].grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/06_likes_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 06_likes_analysis.png")

        print("âœ… ç”µå½±åˆ†æå®Œæˆï¼")

    def time_trend_analysis(self):
        """
        æ—¶é—´è¶‹åŠ¿åˆ†æ
        """
        print("\nğŸ“… å¼€å§‹æ—¶é—´è¶‹åŠ¿åˆ†æ...")

        # 1. æŒ‰å¹´ç»Ÿè®¡
        print("   - åˆ†æè¯„è®ºæ—¶é—´è¶‹åŠ¿...")
        yearly_stats = self.df.groupby('year').agg({
            'ID': 'count',
            'Score': 'mean',
            'Star': 'mean'
        }).rename(columns={'ID': 'count', 'Score': 'avg_score', 'Star': 'avg_star'})

        fig, axes = plt.subplots(2, 1, figsize=(14, 10))

        # è¯„è®ºæ•°é‡è¶‹åŠ¿
        ax1 = axes[0]
        ax1.plot(yearly_stats.index, yearly_stats['count'],
                marker='o', linewidth=2, markersize=8, color='steelblue')
        ax1.fill_between(yearly_stats.index, yearly_stats['count'], alpha=0.3, color='steelblue')
        ax1.set_xlabel('å¹´ä»½', fontsize=12)
        ax1.set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
        ax1.set_title('å†å¹´è¯„è®ºæ•°é‡è¶‹åŠ¿', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)

        # æ·»åŠ æ•°æ®æ ‡ç­¾
        for x, y in zip(yearly_stats.index, yearly_stats['count']):
            ax1.text(x, y, f'{int(y)}', ha='center', va='bottom', fontsize=9)

        # è¯„åˆ†å’Œæ˜Ÿçº§è¶‹åŠ¿
        ax2 = axes[1]
        ax2_twin = ax2.twinx()

        line1 = ax2.plot(yearly_stats.index, yearly_stats['avg_score'],
                        marker='s', linewidth=2, markersize=8, color='green', label='å¹³å‡ç”µå½±è¯„åˆ†')
        line2 = ax2_twin.plot(yearly_stats.index, yearly_stats['avg_star'],
                             marker='^', linewidth=2, markersize=8, color='orange', label='å¹³å‡ç”¨æˆ·æ˜Ÿçº§')

        ax2.set_xlabel('å¹´ä»½', fontsize=12)
        ax2.set_ylabel('å¹³å‡ç”µå½±è¯„åˆ†', fontsize=12, color='green')
        ax2_twin.set_ylabel('å¹³å‡ç”¨æˆ·æ˜Ÿçº§', fontsize=12, color='orange')
        ax2.tick_params(axis='y', labelcolor='green')
        ax2_twin.tick_params(axis='y', labelcolor='orange')
        ax2.set_title('å†å¹´è¯„åˆ†å’Œæ˜Ÿçº§è¶‹åŠ¿', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)

        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax2.legend(lines, labels, loc='best', fontsize=10)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/07_time_trend.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 07_time_trend.png")

        # 2. æŒ‰æœˆç»Ÿè®¡ï¼ˆä»…ç»Ÿè®¡æ•°æ®é‡è¾ƒå¤§çš„å¹´ä»½ï¼‰
        print("   - åˆ†ææœˆåº¦è¶‹åŠ¿...")
        monthly_stats = self.df.groupby('year_month').agg({
            'ID': 'count',
            'sentiment': lambda x: (x == 'æ­£é¢').sum() / len(x) * 100
        }).rename(columns={'ID': 'count', 'sentiment': 'positive_rate'})

        fig, axes = plt.subplots(2, 1, figsize=(16, 10))

        # æœˆåº¦è¯„è®ºé‡
        axes[0].plot(range(len(monthly_stats)), monthly_stats['count'],
                    linewidth=1.5, color='steelblue', alpha=0.8)
        axes[0].fill_between(range(len(monthly_stats)), monthly_stats['count'],
                            alpha=0.3, color='steelblue')
        axes[0].set_xlabel('æ—¶é—´', fontsize=12)
        axes[0].set_ylabel('è¯„è®ºæ•°é‡', fontsize=12)
        axes[0].set_title('æœˆåº¦è¯„è®ºæ•°é‡è¶‹åŠ¿', fontsize=14, fontweight='bold')
        axes[0].grid(True, alpha=0.3)

        # æœˆåº¦æ­£é¢è¯„è®ºç‡
        axes[1].plot(range(len(monthly_stats)), monthly_stats['positive_rate'],
                    linewidth=1.5, color='green', alpha=0.8)
        axes[1].fill_between(range(len(monthly_stats)), monthly_stats['positive_rate'],
                            alpha=0.3, color='green')
        axes[1].set_xlabel('æ—¶é—´', fontsize=12)
        axes[1].set_ylabel('æ­£é¢è¯„è®ºå æ¯” (%)', fontsize=12)
        axes[1].set_title('æœˆåº¦æ­£é¢è¯„è®ºç‡è¶‹åŠ¿', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        axes[1].axhline(monthly_stats['positive_rate'].mean(),
                       color='red', linestyle='--', linewidth=2,
                       label=f'å¹³å‡å€¼: {monthly_stats["positive_rate"].mean():.1f}%')
        axes[1].legend(fontsize=10)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/08_monthly_trend.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 08_monthly_trend.png")

        # æ·»åŠ åˆ°æŠ¥å‘Š
        self.report.append("## å››ã€æ—¶é—´è¶‹åŠ¿åˆ†æ\n")
        self.report.append(f"- **æ—¶é—´è·¨åº¦**: {self.df['year'].min()} - {self.df['year'].max()} å¹´\n")
        self.report.append(f"- **è¯„è®ºé«˜å³°å¹´ä»½**: {yearly_stats['count'].idxmax()} å¹´ ({int(yearly_stats['count'].max())} æ¡)\n")
        self.report.append(f"- **å¹³å‡æ­£é¢è¯„è®ºç‡**: {monthly_stats['positive_rate'].mean():.2f}%\n\n")

        print("âœ… æ—¶é—´è¶‹åŠ¿åˆ†æå®Œæˆï¼")

    def correlation_analysis(self):
        """
        ç›¸å…³æ€§åˆ†æ
        """
        print("\nğŸ”— å¼€å§‹ç›¸å…³æ€§åˆ†æ...")

        # å‡†å¤‡æ•°å€¼æ•°æ®
        numeric_cols = ['Score', 'Star', 'Like', 'comment_length']
        corr_matrix = self.df[numeric_cols].corr()

        fig, axes = plt.subplots(1, 2, figsize=(16, 6))

        # ç›¸å…³æ€§çƒ­åŠ›å›¾
        sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm',
                   center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8},
                   ax=axes[0])
        axes[0].set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, fontweight='bold', pad=15)

        # æƒ…æ„Ÿ-æ˜Ÿçº§äº¤å‰è¡¨
        sentiment_star = pd.crosstab(self.df['sentiment'], self.df['Star'], normalize='columns') * 100
        sns.heatmap(sentiment_star, annot=True, fmt='.1f', cmap='YlGnBu',
                   square=False, linewidths=1, cbar_kws={"shrink": 0.8},
                   ax=axes[1])
        axes[1].set_title('æƒ…æ„Ÿ-æ˜Ÿçº§åˆ†å¸ƒçƒ­åŠ›å›¾ (%)', fontsize=14, fontweight='bold', pad=15)
        axes[1].set_xlabel('æ˜Ÿçº§', fontsize=12)
        axes[1].set_ylabel('æƒ…æ„Ÿ', fontsize=12)

        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/09_correlation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 09_correlation_heatmap.png")

        # æ•£ç‚¹å›¾çŸ©é˜µ
        print("   - ç”Ÿæˆæ•£ç‚¹å›¾çŸ©é˜µ...")
        sample_df = self.df.sample(min(5000, len(self.df)), random_state=42)

        fig = plt.figure(figsize=(14, 14))

        for i, col1 in enumerate(numeric_cols):
            for j, col2 in enumerate(numeric_cols):
                ax = plt.subplot(4, 4, i*4 + j + 1)

                if i == j:
                    ax.hist(sample_df[col1], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
                    ax.set_ylabel('é¢‘æ•°', fontsize=9)
                else:
                    ax.scatter(sample_df[col2], sample_df[col1],
                             alpha=0.3, s=10, color='steelblue')

                if i == 3:
                    ax.set_xlabel(col2, fontsize=9)
                if j == 0:
                    ax.set_ylabel(col1, fontsize=9)

                ax.grid(True, alpha=0.3)

        plt.suptitle('ç‰¹å¾æ•£ç‚¹å›¾çŸ©é˜µ', fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/10_scatter_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 10_scatter_matrix.png")

        # æ·»åŠ åˆ°æŠ¥å‘Š
        self.report.append("## äº”ã€ç›¸å…³æ€§åˆ†æ\n")
        self.report.append("### å…³é”®å‘ç°\n")
        self.report.append(f"- **è¯„åˆ†ä¸æ˜Ÿçº§ç›¸å…³æ€§**: {corr_matrix.loc['Score', 'Star']:.3f}\n")
        self.report.append(f"- **ç‚¹èµä¸æ˜Ÿçº§ç›¸å…³æ€§**: {corr_matrix.loc['Like', 'Star']:.3f}\n")
        self.report.append(f"- **è¯„è®ºé•¿åº¦ä¸æ˜Ÿçº§ç›¸å…³æ€§**: {corr_matrix.loc['comment_length', 'Star']:.3f}\n\n")

        print("âœ… ç›¸å…³æ€§åˆ†æå®Œæˆï¼")

    def comprehensive_dashboard(self):
        """
        ç”Ÿæˆç»¼åˆä»ªè¡¨æ¿
        """
        print("\nğŸ“Š ç”Ÿæˆç»¼åˆåˆ†æä»ªè¡¨æ¿...")

        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

        # 1. è¯„åˆ†åˆ†å¸ƒ
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.hist(self.df['Score'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
        ax1.set_title('è¯„åˆ†åˆ†å¸ƒ', fontweight='bold')
        ax1.set_xlabel('è¯„åˆ†')
        ax1.set_ylabel('ç”µå½±æ•°')

        # 2. æ˜Ÿçº§é¥¼å›¾
        ax2 = fig.add_subplot(gs[0, 1])
        star_counts = self.df['Star'].value_counts().sort_index()
        colors = ['#ff6b6b', '#f06595', '#ffa500', '#74c0fc', '#51cf66']
        ax2.pie(star_counts.values, labels=[f'{i}æ˜Ÿ' for i in star_counts.index],
               autopct='%1.1f%%', colors=colors, startangle=90)
        ax2.set_title('æ˜Ÿçº§åˆ†å¸ƒ', fontweight='bold')

        # 3. æƒ…æ„Ÿé¥¼å›¾
        ax3 = fig.add_subplot(gs[0, 2])
        sentiment_counts = self.df['sentiment'].value_counts()
        sentiment_colors = {'æ­£é¢': '#51cf66', 'ä¸­æ€§': '#ffa500', 'è´Ÿé¢': '#ff6b6b'}
        ax3.pie(sentiment_counts.values, labels=sentiment_counts.index,
               autopct='%1.1f%%', colors=[sentiment_colors[s] for s in sentiment_counts.index],
               startangle=90)
        ax3.set_title('æƒ…æ„Ÿåˆ†å¸ƒ', fontweight='bold')

        # 4. å¹´åº¦è¶‹åŠ¿
        ax4 = fig.add_subplot(gs[1, :])
        yearly_stats = self.df.groupby('year').size()
        ax4.plot(yearly_stats.index, yearly_stats.values, marker='o', linewidth=2, markersize=8)
        ax4.fill_between(yearly_stats.index, yearly_stats.values, alpha=0.3)
        ax4.set_title('å†å¹´è¯„è®ºæ•°é‡è¶‹åŠ¿', fontweight='bold')
        ax4.set_xlabel('å¹´ä»½')
        ax4.set_ylabel('è¯„è®ºæ•°')
        ax4.grid(True, alpha=0.3)

        # 5. TOP10ç”µå½±
        ax5 = fig.add_subplot(gs[2, :])
        movie_counts = self.df['Movie_Name'].value_counts().head(10)
        movies = [m[:20]+'...' if len(m) > 20 else m for m in movie_counts.index]
        bars = ax5.barh(range(len(movies)), movie_counts.values,
                       color=plt.cm.Spectral(np.linspace(0, 1, len(movies))))
        ax5.set_yticks(range(len(movies)))
        ax5.set_yticklabels(movies)
        ax5.invert_yaxis()
        ax5.set_title('TOP 10 è¯„è®ºæœ€å¤šçš„ç”µå½±', fontweight='bold')
        ax5.set_xlabel('è¯„è®ºæ•°')
        ax5.grid(axis='x', alpha=0.3)

        plt.suptitle('å½±è¯„æ•°æ®åˆ†æç»¼åˆä»ªè¡¨æ¿', fontsize=18, fontweight='bold', y=0.995)
        plt.savefig(f'{self.output_dir}/11_comprehensive_dashboard.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"     âœ… ä¿å­˜: 11_comprehensive_dashboard.png")

        print("âœ… ç»¼åˆä»ªè¡¨æ¿ç”Ÿæˆå®Œæˆï¼")

    def generate_report(self):
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        """
        print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        # æ·»åŠ æ€»ç»“
        self.report.append("## å…­ã€åˆ†ææ€»ç»“\n")
        self.report.append("### ä¸»è¦å‘ç°\n")
        self.report.append(f"1. **æ•°æ®è§„æ¨¡**: å…±åˆ†æäº† {len(self.df)} æ¡å½±è¯„ï¼Œæ¶µç›– {self.df['Movie_Name'].nunique()} éƒ¨ç”µå½±\n")
        self.report.append(f"2. **æƒ…æ„Ÿå€¾å‘**: æ­£é¢è¯„è®ºå æ¯”æœ€é«˜ï¼Œè¾¾åˆ° {(self.df['sentiment']=='æ­£é¢').sum()/len(self.df)*100:.1f}%\n")
        self.report.append(f"3. **è¯„åˆ†åˆ†å¸ƒ**: å¹³å‡è¯„åˆ† {self.df['Score'].mean():.2f}ï¼Œä¸­ä½æ•° {self.df['Score'].median():.2f}\n")
        self.report.append(f"4. **ç”¨æˆ·å‚ä¸**: å¹³å‡æ¯éƒ¨ç”µå½±è·å¾— {len(self.df)/self.df['Movie_Name'].nunique():.0f} æ¡è¯„è®º\n")
        self.report.append(f"5. **äº’åŠ¨æƒ…å†µ**: {(self.df['Like']>0).sum()} æ¡è¯„è®ºè·å¾—ç‚¹èµï¼Œå æ¯” {(self.df['Like']>0).sum()/len(self.df)*100:.1f}%\n\n")

        self.report.append("### å¯è§†åŒ–å›¾è¡¨æ¸…å•\n")
        self.report.append("1. `01_sentiment_distribution.png` - æƒ…æ„Ÿä¸æ˜Ÿçº§åˆ†å¸ƒ\n")
        self.report.append("2. `02_score_distribution.png` - è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾\n")
        self.report.append("3. `03_top_keywords.png` - é«˜é¢‘å…³é”®è¯æŸ±çŠ¶å›¾\n")
        self.report.append("4. `04_wordcloud.png` - è¯äº‘å›¾ï¼ˆå…¨éƒ¨/æ­£é¢/è´Ÿé¢ï¼‰\n")
        self.report.append("5. `05_top_movies.png` - çƒ­é—¨ç”µå½±æ’è¡Œæ¦œ\n")
        self.report.append("6. `06_likes_analysis.png` - ç‚¹èµæ•°åˆ†æ\n")
        self.report.append("7. `07_time_trend.png` - å¹´åº¦è¶‹åŠ¿åˆ†æ\n")
        self.report.append("8. `08_monthly_trend.png` - æœˆåº¦è¶‹åŠ¿åˆ†æ\n")
        self.report.append("9. `09_correlation_heatmap.png` - ç›¸å…³æ€§çƒ­åŠ›å›¾\n")
        self.report.append("10. `10_scatter_matrix.png` - æ•£ç‚¹å›¾çŸ©é˜µ\n")
        self.report.append("11. `11_comprehensive_dashboard.png` - ç»¼åˆä»ªè¡¨æ¿\n\n")

        self.report.append("---\n")
        self.report.append("*æœ¬æŠ¥å‘Šç”±å½±è¯„æ•°æ®æŒ–æ˜ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n")

        # ä¿å­˜æŠ¥å‘Š
        report_path = f'{self.output_dir}/analysis_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.writelines(self.report)

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    def _load_stopwords(self):
        """
        åŠ è½½ä¸­æ–‡åœç”¨è¯è¡¨
        """
        # å¸¸ç”¨ä¸­æ–‡åœç”¨è¯
        stopwords = set([
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€',
            'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€',
            'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'é‚£', 'ä¹ˆ', 'ä¸º', 'è¿™ä¸ª', 'æ¥',
            'ä¸ª', 'ä¸­', 'å¤§', 'é‡Œ', 'å¯', 'èƒ½', 'ä½†', 'è€Œ', 'ä¸', 'ç»™', 'å¯¹',
            'è¢«', 'ä»', 'è¿˜', 'è®©', 'æŠŠ', 'åˆ', 'æ›´', 'å—', 'æ—¶', 'åœ°', 'å¾—',
            'å•Š', 'å§', 'å‘¢', 'å“¦', 'å“ˆ', 'å—¯', 'å‘€', 'å•¦', 'å˜›', 'å—',
            'ç”µå½±', 'å½±ç‰‡', 'éƒ¨', 'ç‰‡', 'è¿™éƒ¨', 'ä¸€éƒ¨', 'è§‰å¾—', 'æ„Ÿè§‰', 'çœŸçš„',
            'å¤ª', 'æŒº', 'ç‰¹åˆ«', 'éå¸¸', 'ååˆ†', 'æ¯”è¾ƒ', 'è¿˜æ˜¯', 'å·²ç»', 'å°±æ˜¯',
            'å¯ä»¥', 'æ‰€ä»¥', 'å¦‚æœ', 'è™½ç„¶', 'å› ä¸º', 'ä½†æ˜¯', 'ç„¶å', 'æœ€å',
            'ã€€', ' ', '\n', '\t', '\r'
        ])

        return stopwords

    def run(self):
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        """
        try:
            # åŠ è½½æ•°æ®
            self.load_data()

            # æ•°æ®é¢„å¤„ç†
            self.preprocess_data()

            # æƒ…æ„Ÿåˆ†æ
            self.sentiment_analysis()

            # å…³é”®è¯åˆ†æ
            self.keyword_analysis()

            # ç”µå½±åˆ†æ
            self.movie_analysis()

            # æ—¶é—´è¶‹åŠ¿åˆ†æ
            self.time_trend_analysis()

            # ç›¸å…³æ€§åˆ†æ
            self.correlation_analysis()

            # ç»¼åˆä»ªè¡¨æ¿
            self.comprehensive_dashboard()

            # ç”ŸæˆæŠ¥å‘Š
            self.generate_report()

            print("\n" + "=" * 60)
            print("ğŸ‰ æ‰€æœ‰åˆ†æä»»åŠ¡å®Œæˆï¼")
            print("=" * 60)
            print(f"\nğŸ“ åˆ†æç»“æœä¿å­˜åœ¨ç›®å½•: {self.output_dir}/")
            print(f"ğŸ“Š å…±ç”Ÿæˆ 11 å¼ å¯è§†åŒ–å›¾è¡¨")
            print(f"ğŸ“„ åˆ†ææŠ¥å‘Š: {self.output_dir}/analysis_report.md")
            print("\næ„Ÿè°¢ä½¿ç”¨å½±è¯„æ•°æ®æŒ–æ˜åˆ†æç³»ç»Ÿï¼")

        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == '__main__':
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    data_path = 'data.xlsx'

    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = FilmReviewAnalyzer(data_path)

    # è¿è¡Œåˆ†æ
    analyzer.run()
